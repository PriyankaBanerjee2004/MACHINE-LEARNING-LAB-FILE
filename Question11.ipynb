{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMq0AbVIqygSwRkqtmoutvc"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wYu71d6p2Omc","executionInfo":{"status":"ok","timestamp":1762595001456,"user_tz":-330,"elapsed":21,"user":{"displayName":"Priyanka Banerjee","userId":"10242902359885555381"}},"outputId":"1b356a40-84b2-4362-f2d9-b1147835d0eb"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","XOR using Perceptron Network:\n","\n","Input: [0 0] --> XOR Output: 0\n","Input: [0 1] --> XOR Output: 1\n","Input: [1 0] --> XOR Output: 1\n","Input: [1 1] --> XOR Output: 0\n"]}],"source":["import numpy as np\n","\n","# Activation Function (Step Function)\n","def step(x):\n","    return 1 if x >= 0 else 0\n","\n","# Perceptron class\n","class Perceptron:\n","    def __init__(self, weights, bias):\n","        self.weights = np.array(weights)\n","        self.bias = bias\n","\n","    def predict(self, x):\n","        total = np.dot(self.weights, x) + self.bias\n","        return step(total)\n","\n","# Define perceptrons for hidden layer\n","# h1: OR gate\n","h1 = Perceptron(weights=[1, 1], bias=-0.5)\n","\n","# h2: AND gate\n","h2 = Perceptron(weights=[1, 1], bias=-1.5)\n","\n","# Output Layer: h1 AND (NOT h2)\n","output_p = Perceptron(weights=[1, -1], bias=-0.5)\n","\n","# Test XOR\n","inputs = np.array([[0,0], [0,1], [1,0], [1,1]])\n","\n","print(\"\\nXOR using Perceptron Network:\\n\")\n","for x in inputs:\n","    h1_out = h1.predict(x)\n","    h2_out = h2.predict(x)\n","    y = output_p.predict([h1_out, h2_out])\n","    print(f\"Input: {x} --> XOR Output: {y}\")\n"]}]}